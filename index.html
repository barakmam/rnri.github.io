<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="description"
          content="Regularized Newton Raphson Inversion used to invert and edit images using text to image diffusion models.">
    <meta name="keywords" content="RNRI, Inversion, Image-editing, Diffusion Model">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>RNRI: Regularized Newton Raphson Inversion for Text-to-Image Diffusion Models</title>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
          rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet"
          href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/icon.png">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
    </script>
    <script type="text/javascript"
            src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
    </script>

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
    <div class="hero-body">
        <div class="container is-max-desktop">
            <div class="columns is-centered">
                <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title">
                        RNRI: Regularized Newton Raphson Inversion for Text-to-Image Diffusion Models</h1>
                    <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/dvirsamuel">Dvir Samuel</a><sup>1,3</sup>,</span>
                        <span class="author-block">
              <a href="https://github.com/barakmam">Barak Meiri</a><sup>1,2</sup>,</span>
                        <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Mf06N8kAAAAJ&hl=en">Nir Darshan</a><sup>1</sup>,
            </span>
                        <span class="author-block">
              <a href="https://scholar.google.com/citations?user=Wk2gAZUAAAAJ&hl=iw">Gal Chechik</a><sup>3,4</sup>,
            </span>
                        <span class="author-block">
              <a href="https://scholar.google.com/citations?user=hpItE1QAAAAJ&hl=en">Shai Avidan</a><sup>2</sup>,
            </span>
                        <span class="author-block">
              <a href="http://www.benarirami.com">Rami Ben-Ari</a><sup>1</sup>,
            </span>
                    </div>

                    <div class="is-size-5 publication-authors">
                        <span class="author-block"><sup>1</sup>OriginAI,</span>
                        <span class="author-block"><sup>2</sup>Tel Aviv University,</span>
                        <span class="author-block"><sup>3</sup>Bar Ilan University,</span>
                        <span class="author-block"><sup>4</sup>NVIDIA Research</span>
                    </div>

                    <div class="column has-text-centered">
                        <div class="publication-links">
                            <!-- PDF Link. -->
                            <span class="link-block">
<!--                <a href="https://arxiv.org/pdf/2011.12948"-->
                <a href="https://arxiv.org/pdf/link_to_your_paper"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
                            <!-- Code Link. -->
                            <span class="link-block">
<!--                <a href="https://github.com/your_github_repo"-->
                                <!--                   class="external-link button is-normal is-rounded is-dark">-->
                <a class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code - coming soon</span>
                  </a>
              </span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<!-- First Image. -->
<section class="hero teaser">
    <div class="container is-max-desktop">
        <div class="hero-body">
            <img src="./static/images/figure1_editing.png" alt="">
            <h2 class="subtitle has-text-centered">
                Image editing using our RNRI for inversion demonstrates significant speed-up
                and improved quality compared to previous state-of-the-art methods.
                Results are shown for both Latent Diffusion models and fast Latent consistency models.
            </h2>
        </div>
    </div>
</section>

<!-- Videos Carousel. -->
<section class="hero is-light is-small">
    <div class="hero-body">
        <div class="container column is-three-fifths">
            <h2 class="title is-3 has-text-centered">Real Time Videos</h2>
            <div id="results-carousel" class="carousel results-carousel">
                <div class="item item-cat">
                    <video id="cat" autoplay controls muted loop playsinline height="100%">
                        <source src="./static/videos/cat.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item item-chair-tp">
                    <video id="wine" autoplay controls muted loop playsinline height="100%">
                        <source src="./static/videos/wine.mp4" type="video/mp4">
                    </video>
                </div>
                <div class="item item-shiba">
                    <video id="lion" autoplay controls muted loop playsinline height="100%">
                        <source src="./static/videos/lion.mp4" type="video/mp4">
                    </video>
                </div>
            </div>
            <h2 class="subtitle has-text-centered">
                The videos are running in real time speed.
                RNRI enables fast and accurate text-to-image editing using diffusion models.
            </h2>
        </div>
    </div>
</section>


<!-- More Editing Results. -->
<section class="hero">
    <div class="container is-max-desktop is-centered">
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <div class="hero-body">
                    <h2 class="title is-3">Editing Examples</h2>
                    <img src="./static/images/supp_editing_same.png" alt="">
                    <h2 class="subtitle has-text-centered">
                        Various editing with same input: Note the RNRI capability in both subtle
                        and extensive changes as one would expect from the particular prompt change.
                    </h2>
                </div>
            </div>
        </div>
    </div>
</section>

<!--<div class="card">-->
<!--  <div class="card-image">-->
<!--    <figure class="image is-2 is-covered">-->
<!--      <img src="./static/images/interpolate_end.jpg" alt="" />-->
<!--    </figure>-->
<!--  </div>-->
<!--    <div class="card-content slider-text">-->
<!--      <div class="is-size-2 box">-->
<!--          YOUR_IMAGE_CAPTION_HERE-->
<!--      </div>-->
<!--  </div>-->
<!--</div>-->

<section class="section">
    <div class="hero is-light is-small">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered ">
                <div class="column is-four-fifths">
                    <br>
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            Diffusion inversion is the problem of taking an image and a text prompt that describes it,
                            and finding a noise latent that would generate the image. Most current inversion techniques
                            operate by approximately solving an implicit equation, and may converge slowly or yield poor
                            reconstructed images.
                        </p>
                        <p>
                            Here, we formulate the problem as finding the roots of an implicit equation and design a
                            method
                            to solve it efficiently. Our solution is based on Newton-Raphson (NR), a well-known
                            technique in
                            numerical analysis. A naive application of NR may be computationally infeasible and tends to
                            converge to incorrect solutions.
                            We describe an efficient regularized formulation that converges quickly to solution that
                            provide
                            high-quality reconstructions.
                            We also identify a source of inconsistency stemming from prompt conditioning during the
                            inversion
                            process, which significantly degrades the inversion quality. To address this, we introduce a
                            prompt-aware adjustment of the encoding, effectively correcting this issue.
                        </p>
                        <p>
                            Our solution, <b>R</b>egularized <b>N</b>ewton-<b>R</b>aphson <b>I</b>nversion, inverts an
                            image within 0.5 sec for
                            latent consistency models, opening the door for interactive image editing.
                            We further demonstrate improved results in image interpolation and generation of rare
                            objects.
                            <br>
                            <br>
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <!--/ Abstract. -->
    </div>
    <div class="container is-max-desktop">
        <!-- NRI_diagram. -->
        <br>
        <div class="columns is-centered has-text-centered">
            <div class="column is-four-fifths">
                <h2 class="title is-3">Inversion Pipeline</h2>
                <img src="./static/images/NRI_diagram.png" alt="">
                Newton-Raphson Inversion iterates over the obejective function $\mathcal{F}(z_t)$. at every time step in
                the inversion path. It starts with $z_t^0=z_{t-1}$ and quickly converges (within 2 iterations) to $z_t$.
                Each box denotes one inversion step; black circles correspond to intermediate latents in the denoising
                process; green circles correspond to intermediate Newton-Raphson iterations.
            </div>
        </div>
        <!--/ NRI_diagram. -->
    </div>
</section>

<div class="container is-max-desktop">
    <!-- PSNR Results. -->
    <br>
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
            <h2 class="title is-3">PSNR & Run Time Results</h2>
            <img src="./static/images/psnr_iter.png" alt="">
            (a) Convergence rate. Comparison of iterative methods in an image inversion-reconstruction task over the
            COCO validation set. The mean PSNR of reconstructed images is
            plotted against the number of iterations. The dashed line represents the upper bound on reconstruction
            quality determined by the VAE in Stable Diffusion. Mean convergence time (in seconds) is
            denoted for each method. Our RNRI achieves a PSNR close to the upper limit and converges within
            only 1-2 iterations. <br>(b) Prior effect on convergence. Incorporating our prior not only aids in finding
            the correct solution but also accelerates convergence.
        </div>
    </div>
    <!--/ PSNR Results. -->
</div>
<!--BibTeX-->
<!--<section class="section" id="BibTeX">-->
<!--  <div class="container is-max-desktop content">-->
<!--    <h2 class="title">BibTeX</h2>-->
<!--    <pre><code>@article{park2021nerfies,-->
<!--  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},-->
<!--  title     = {Nerfies: Deformable Neural Radiance Fields},-->
<!--  journal   = {ICCV},-->
<!--  year      = {2021},-->
<!--}</code></pre>-->
<!--  </div>-->
<!--</section>-->
<!-- / BibTeX-->


<footer class="footer">
    <div class="container">
        <div class="content has-text-centered">
            <a class="icon-link">
                <!--            <a class="icon-link"-->
                <!--               href="./static/paper/your_paper.pdf">-->
                <i class="fas fa-file-pdf"></i>
            </a>
            <!--            <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>-->
            <!--                <i class="fab fa-github"></i>-->
            <!--            </a>-->
        </div>
        <div class="columns is-centered">
            <div class="column is-8">
                <div class="content">
                    <p>
                        This website is licensed under a
                        <a rel="license" href="https://creativecommons.org/licenses/by-sa/4.0/">Creative
                            Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p>
                    <p>
                        Website source code based on the <a href="https://nerfies.github.io/">Nerfies</a> project page.
                        If you want to reuse their <a href="https://github.com/nerfies/nerfies.github.io">source
                        code</a>, please credit them appropriately.
                    </p>
                </div>
            </div>
        </div>
    </div>
</footer>

</body>
</html>
